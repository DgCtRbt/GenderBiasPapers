# Gender Bias Papers

>  Contributed by [Jishun Zhao](https://github.com/DgCtRbt) and [Shucheng Zhu](https://github.com/zhushucheng).

## Introduction

In this repo, we list some related work on gender bias. Corrections and suggestions are welcomed. 

 <img src="https://www.hh-law.com/wp-content/uploads/sites/1300396/2019/11/implicitbiasimage.jpg" width = "600" height = "400" alt="" align=center />

## Contents

1. [Volume](#Volume)
2. [ArXiv's latest related papers](#ArXiv's-latest-related-papers)
3. [Review article](#Review-article)
4. [Bias analysis](#Bias-analysis)
5. [Bias measurement](#Bias-measurement)
6. [Bias Detection](#Bias-Detection)
7. [Model de-bias](#Model-de-bias)
8. [Text de-bias](#Text-de-bias)
9. [Data set](#Data-set)
10. [Conference](#Conference)
11. [Comment](#Comment )
12. [Psychology](#Psychology)
13. [Relevant literature](#Relevant-literature)
14. [Prompt](#Prompt)
15. [Hate Speech & Abusive language & Cyberbullying](#Hate-Speech-&-Abusive-language-&-Cyberbullying)

## Volume

1. [Proceedings of the First Workshop on Gender Bias in Natural Language Processing](https://www.aclweb.org/anthology/W19-38.pdf)
2. [Proceedings of the Second Workshop on Gender Bias in Natural Language Processing](https://www.aclweb.org/anthology/volumes/2020.gebnlp-1/)
3. [3rd Workshop on Gender Bias in Natural Language Processing](https://genderbiasnlp.talp.cat/)

## ArXiv's latest related papers

1. Back to Square One：Bias Detection, Training and Commonsense Disentanglement in the Winograd Schema.2021.[PDF](https://arxiv.org/abs/2104.08161)
2. Detoxifying Language Models Risks Marginalizing Minority Voices.2021.[PDF](https://arxiv.org/abs/2104.06390)
3. First the Worst：Finding Better Gender Translations during Beam Search.2021.[PDF](https://arxiv.org/abs/2104.07429)
4. Gender Bias in Machine Translation.2021.[PDF](https://arxiv.org/abs/2104.06001)
5. Improving Gender Translation Accuracy with Filtered Self-training.2021.[PDF](https://arxiv.org/abs/2104.07695)
6. Investigating Failures of Automatic Translation in the Case of Unambiguous Gender.2021.2021.[PDF](https://arxiv.org/abs/2104.07838)
7. Quantifying Gender Bias Towards Politicians in Cross-Lingual Language Models.2021.[PDF](https://arxiv.org/abs/2104.07505)
8. Unmasking the Mask - Evaluating Social Biases in Masked Language Models.2021. [PDF](https://arxiv.org/abs/2104.07496)
9. Revealing Persona Biases in Dialogue Systems.2021.[PDF](https://arxiv.org/abs/2104.08728)
10. Hidden Biases in Unreliable News Detection Datasets.2021.[PDF](https://arxiv.org/abs/2104.10130)
11. Identifying Offensive Expressions of Opinion in Context.2021.[PDF](https://arxiv.org/abs/2104.12227)
12. Contextual Lexicon-Based Approach for Hate Speech and Offensive Language Detection.2021.[PDF](https://arxiv.org/abs/2104.12265)
13. Impact of Gender Debiased Word Embeddings in Language Modeling.2021.[PDF](https://arxiv.org/abs/2105.00908)
14. The Authors Matter: Understanding and Mitigating Implicit Bias in Deep Text Classification.2021.[PDF](https://arxiv.org/abs/2105.02778)
15. Societal Biases in Language Generation: Progress and Challenges.2021.[PDF](https://arxiv.org/abs/2105.04054)
16. Evaluating Gender Bias in Natural Language Inference.2021.[PDF](https://arxiv.org/abs/2105.05541)
17. Multilingual Offensive Language Identification for Low-resource Languages.2021.[PDF](https://arxiv.org/abs/2105.05996)
18. Black or White but Never Neutral: How Readers Perceive Identity from Yellow or Skin-toned Emoji.2021.[PDF](https://arxiv.org/abs/2105.05887)
19. The Incel Lexicon: Deciphering the Emergent Cryptolect of a Global Misogynistic Community.2021.[PDF](https://arxiv.org/abs/2105.12006)
20. MBIC - A Media Bias Annotation Dataset Including Annotator Characteristics.2021.[PDF](https://arxiv.org/abs/2105.11910)
21. How to Split: The Effect of Word Segmentation on Gender Bias in Speech Translation.2021.[PDF](https://arxiv.org/abs/2105.13782)
22. A Simple Voting Mechanism for Online Sexist Content Identification.2021.[PDF](https://arxiv.org/abs/2105.14309)
23. LPF: A Language-Prior Feedback Objective Function for De-biased Visual Question Answering.2021.[PDF](https://arxiv.org/abs/2105.14300)
24. Gender Bias Amplification During Speed-Quality Optimization in Neural  Machine Translation.2021.[PDF](https://arxiv.org/abs/2106.00169)
25. Gender Bias Hidden Behind Chinese Word Embeddings: The Case of Chinese  Adjectives.2021.[PDF](https://arxiv.org/abs/2106.00181)
26. John Praised Mary Because He? Implicit Causality Bias and Its Interaction with Explicit Cues in LMs.2021.[PDF](https://arxiv.org/abs/2106.01060)
27. Men Are Elected, Women Are Married: Events Gender Bias on Wikipedia.2021.[PDF](https://arxiv.org/abs/2106.01601)
28. Understanding and Countering Stereotypes: A Computational Approach to  the Stereotype Content Model.2021.[PDF](https://arxiv.org/abs/2106.02596)
29. Towards Equal Gender Representation in the Annotations of Toxic Language  Detection.2021.[PDF](https://arxiv.org/abs/2106.02183)
30. A Diachronic Evaluation of Gender Asymmetry in Euphemism.2021.[PDF](https://arxiv.org/abs/2106.02083)
31. LGBTQ-AI? Exploring Expressions of Gender and Sexual Orientation in Chatbots.2021.[PDF](https://arxiv.org/abs/2106.02076)
32. RedditBias: A Real-World Resource for Bias Evaluation and Debiasing of Conversational Language Models.2021.[PDF](https://arxiv.org/abs/2106.03521)
33. Automatic Sexism Detection with Multilingual Transformer Models.2021.[PDF](https://arxiv.org/abs/2106.04908)
34. Stereotype and Skew: Quantifying Gender Bias in Pre-trained and Fine-tuned Language Models.2021.EACL.[PDF](https://www.aclweb.org/anthology/2021.eacl-main.190/)
35. Ruddit: Norms of Offensiveness for English Reddit Comments.2021.[PDF](https://arxiv.org/abs/2106.05664)
36. Evaluating Gender Bias in Hindi-English Machine Translation.2021.[PDF](https://arxiv.org/abs/2106.08680)
37. Subjective Bias in Abstractive Summarization.2021.[PDF](https://arxiv.org/abs/2106.10084)
38. Predicting Gender of Brazilian Names Using Deep Learning.2021.[PDF](https://arxiv.org/abs/2106.10156)
39. A Survey of Race, Racism, and Anti-Racism in NLP.2021.[PDF](https://arxiv.org/abs/2106.11410)
40. On Positivity Bias in Negative Reviews.2021.[PDF](https://arxiv.org/abs/2106.12056)
41. Towards Understanding and Mitigating Social Biases in Language Models.2021.[PDF](https://arxiv.org/abs/2106.13219)
42. A Source-Criticism Debiasing Method for GloVe Embeddings.2021.[PDF](https://arxiv.org/abs/2106.13382)
43. Quantifying Social Biases in NLP: A Generalization and Empirical Comparison of Extrinsic Fairness Metrics.2021.[PDF](https://arxiv.org/abs/2106.14574)
44. On the Interaction of Belief Bias and Explanations.2021.[PDF](https://arxiv.org/abs/2106.15355)
45. Sexism in the Judiciary.2021.[PDF](https://arxiv.org/abs/2106.15103)
46. Gender Recognition in Informal and Formal Language Scenarios via Transfer Learning.2021.[PDF](https://arxiv.org/abs/2107.02759)
47. Generating Gender Augmented Data for NLP.2021.[PDF](https://arxiv.org/abs/2107.05987)


## Review article

1. Mitigating Gender Bias in Natural Language Processing: Literature Review.2019.[PDF](https://arxiv.org/abs/1906.08976v1)
2. Predictive Biases in Natural Language Processing Models: A Conceptual Framework and Overview.2020.[PDF](https://arxiv.org/abs/1912.11078)
3. Language (Technology) is Power: A Critical Survey of “Bias” in NLP.2020.ACL.[PDF](https://www.aclweb.org/anthology/2020.acl-main.485/)
4. Societal Biases in Language Generation: Progress and Challenges.2021.ACL.[PDF](https://arxiv.org/abs/2105.04054)


## Bias analysis

1. Man Is to Computer Programmer as Woman Is to Homemaker? Debiasing Word Embeddings.2016.[PDF](https://arxiv.org/abs/1607.06520)
2. Gender Bias and Sexism in Language.2017.[PDF](https://oxfordre.com/communication/view/10.1093/acrefore/9780190228613.001.0001/acrefore-9780190228613-e-470#acrefore-9780190228613-e-470-div1-8)
3. Men Also Like Shopping: Reducing Gender Bias Amplification Using Corpus-level Constraints.2017.EMNLP(Best Long Paper).[PDF](https://arxiv.org/pdf/1707.09457.pdf)
4. Word Embeddings Quantify 100 Years of Gender and Ethnic Stereotypes.2018.[PDF](https://arxiv.org/abs/1711.08412v1).[Code](https://github.com/nikhgarg/EmbeddingDynamicStereotypes)
5. Understanding the Origins of Bias in Word Embeddings.2018.[PDF](https://arxiv.org/abs/1810.03611)
6. Is there Gender bias and stereotype in Portuguese Word Embeddings?.2018.[PDF](https://arxiv.org/abs/1810.04528)
7. Learning Gender-Neutral Word Embeddings.2018.EMNLP.[PDF](https://arxiv.org/abs/1809.01496v1)
8. Measuring Societal Biases from Text Corpora with Smoothed First-Order Co-occurrence.2018.[PDF](https://arxiv.org/abs/1812.10424)
9. Measuring and Mitigating Unintended Bias in Text Classification.2018.AAAI.[PDF](https://dl.acm.org/doi/pdf/10.1145/3278721.3278729)
10. Gender Bias in Sentiment Analysis.2018.[PDF](https://wlv.openrepository.com/bitstream/handle/2436/620633/GenderBiasInSentimentAnalysisPreprint.pdf?sequence=9&isAllowed=y)
11. Examining Gender and Race Bias in Two Hundred Sentiment Analysis Systems.2018.[PDF](https://arxiv.org/abs/1805.04508)
12. Good Secretaries, Bad Truck Drivers? Occupational Gender Stereotypes in Sentiment Analysis.2019.[PDF](https://arxiv.org/abs/1906.10256v2)
13. Gender Bias in Contextualized Word Embeddings.2019.[PDF](https://arxiv.org/abs/1904.03310)
14. Evaluating the Underlying Gender Bias in Contextualized Word Embeddings.2019.[PDF](https://arxiv.org/abs/1904.08783)
15. Measuring Bias in Contextualized Word Representations.2019.[PDF](https://arxiv.org/abs/1906.07337v1)
16. Examining the Presence of Gender Bias in Customer Reviews Using Word Embedding.2019.[PDF](https://arxiv.org/abs/1902.00496v1)
17. Using Word Embeddings to Examine Gender Bias in Dutch Newspapers, 1950-1990.2019.[PDF](https://www.aclweb.org/anthology/W19-4712/)
18. How Does Grammatical Gender Affect Noun Representations in Gender-Marking Languages?.2019.[PDF](https://arxiv.org/pdf/1910.14161.pdf)
19. Quantifying the Semantic Core of Gender Systems.2019.EMNLP.[PDF](https://arxiv.org/pdf/1910.13497.pdf)
20. Finding Microaggressions in the Wild: A Case for Locating Elusive Phenomena in Social Media Posts.2019.[PDF](https://www.aclweb.org/anthology/D19-1176/)
21. Relating Word Embedding Gender Biases to Gender Gaps: A Cross-Cultural Analysis.2019.ACL.[PDF](https://www.aclweb.org/anthology/W19-3803/)
22. Towards Understanding Gender Bias in Neural Relation Extraction.2020.ACL.[PDF](https://www.aclweb.org/anthology/2020.acl-main.265/)
23. Investigating Potential Factors Associated with Gender Discrimination in Collaborative Recommender Systems.2020.[PDF](https://arxiv.org/abs/2002.07786)
24. Analyzing Gender Bias within Narrative Tropes.2020.[PDF](https://arxiv.org/pdf/2011.00092.pdf)


## Bias measurement

1. Measuring Individual Differences in Implicit Cognition: The Implicit Association Test.1998.[PDF](https://groups.psych.northwestern.edu/rosenfeld/documents/greenwald98IAT.pdf)
2. National Differences in Gender–science Stereotypes Predict National Sex Differences in Science and Math Achievement.2009.PNAS.[PDF](https://www.pnas.org/content/pnas/106/26/10593.full.pdf)
3. First Women, Second Sex: Gender Bias in Wikipedia.2015.[PDF](https://arxiv.org/abs/1502.02341)
4. It's A Man's Wikipedia? Assessing Gender Inequality in An Online Encyclopedia.2015.[PDF](https://arxiv.org/abs/1501.06307)
5. Social Bias in Elicited Natural Language Inference.2017.[PDF](https://www.aclweb.org/anthology/W17-1609.pdf)
6. Semantics Derived Automatically from Language Corpora Contain Human-like Biases.2017.[PDF](https://arxiv.org/abs/1608.07187)
7. Gender Bias in Neural Natural Language Processing.2018.[PDF](https://arxiv.org/abs/1807.11714)
8. Reducing Gender Bias in Abusive Language Detection.2018.[PDF](https://arxiv.org/abs/1808.07231)
9. Gender Bias in Coreference Resolution.2018.[PDF](https://arxiv.org/abs/1804.09301)
10. Mind the GAP: A Balanced Corpus of Gendered Ambiguous Pronouns.2018.[PDF](https://watermark.silverchair.com/tacl_a_00240.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAAAqkwggKlBgkqhkiG9w0BBwagggKWMIICkgIBADCCAosGCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQMPE7Kg3Ht5MYve550AgEQgIICXP0XeqeYbNwTfeu-j1c7Q84pHmZAqEziDs0r7WXaeGBx5LZkRmuTp5wWdWdxFj1tqwjN3l74QyTiz7PiN066qi2gOOvAqATNT07KTu5y-R-2SPSD_ExZBGdkKDnkyGm3zIXwJ7zx7FC78Ud5b-2c5LdYNC7dyBd_4Te-ca3hwUzilZqAezF-IwBTrPTt5to0M-B10aAfHCjgxQRxui_cTtS20pDtnQEor6G9vhZwF9ckwVb47CYSqt4qoL1jDuBMTRuRiKBnr7Qp2pI6YLfRz7gtaB6plzaU_3i6tWXcO4HHPx7K3o0JbJAREUSQ3R9PAPyuUCihdQ6LtxHKRL8QEbZ5rsjSqa4_KgFDgsF7R1gycfsS1g0opxrLXQKpLrZ4ZrQTODPubSewo1Bl0jw_Yy9kKTTYCrrboEQZpwR1f7wThslo5PrykUlIwf-usJ_VP2z1ysV7wZWKQ7jYt7whsj1RNBfnn5JmwGZIOeGSvybhrfipV3qQ1LkiN1vn3XytCY9kYgohgcPyQuZWa4kAVKN5_Un32s3Ijc-7pY8y4MlA-HRfw4IZkpNpKQI2PMGThZZ2RWjJDW7z1mWvKc3-DLH_pRs56OwVTMUEYh5DoCjl57UxLgK9fhVgQGGhlpzQflDCkM-381s_j0KJV-R2aVucdagpOBNlKPriqdH3SCvvw60TEtNH9uALDxpd8AONrOXvOkW3zQvgbni-96SzWcGr6lEfVFo5g5wf8pDnMhYNVfmGEHJ476lMFdwdzaolMJ360aAGMx2s96rDmEl1EQxsSObYhfDFx1H00fo)
11. Toward Gender-inclusive Coreference Resolution.2019.[PDF](https://arxiv.org/abs/1910.13913)
12. Assessing Social and Intersectional Biases in Contextualized Word Representations.2019.NIPS.[PDF](https://arxiv.org/abs/1911.01485)
13. Measuring Gender Bias in Word Embeddings across Domains and Discovering New Gender Bias Word Categories.2019.[PDF](https://www.aclweb.org/anthology/W19-3804.pdf)
14. On Measuring Social Biases in Sentence Encoders.2019.[PDF](https://arxiv.org/abs/1903.10561)
15. Black Is to Criminal as Caucasian Is to Police: Detecting and Removing Multiclass Bias in Word Embeddings.2019.[PDF](https://arxiv.org/abs/1904.04047)
16. Lipstick on A Pig: Debiasing Methods Cover up Systematic Gender Biases in Word Embeddings but Do Not Remove Them.2019.[PDF](https://arxiv.org/abs/1903.03862)
17. Finding Microaggressions in the Wild: A Case for Locating Elusive Phenomena in Social Media Posts.2019.[PDF](https://www.aclweb.org/anthology/D19-1176.pdf)
18. StereoSet: Measuring stereotypical bias in pretrained language models.2020.[PDF](https://arxiv.org/abs/2004.09456v1)

## Bias Detection
1. Automatic recognition of habituals: a three-way classification of clausal aspect.2015.EMNLP.[PDF](https://aclanthology.org/D15-1294.pdf)
2. Identifying Generic Noun Phrases.2015.[PDF](https://aclanthology.org/P10-1005.pdf)
3. Illegal is not a Noun: Linguistic Form for Detection of Pejorative Nominalizations.2017.[PDF](https://aclanthology.org/W17-3014.pdf)
4. Identifying Semantic Edit Intentions from Revisions in Wikipedia.2017.[PDF](https://www.aclweb.org/anthology/D17-1213.pdf)
5. Detecting Biased Statements in Wikipedia.2018.[PDF](https://www.researchgate.net/profile/Besnik-Fetahu-2/publication/324641488_Detecting_Biased_Statements_in_Wikipedia/links/5b7d1b2592851c1e1226bd86/Detecting-Biased-Statements-in-Wikipedia.pdf)
6. Neural Based Statement Classification for Biased Language.2018.[PDF](https://arxiv.org/pdf/1811.05740.pdf)
7. Identifying Framing Bias in Online News.2018.[PDF](https://dl.acm.org/doi/pdf/10.1145/3204948)


## Model de-bias

1. Hateful Symbols or Hateful People? Predictive Features for Hate Speech Detection on Twitter.2016.[PDF](https://www.aclweb.org/anthology/N16-2013.pdf)
2. Gender Bias in Coreference Resolution: Evaluation and Debiasing Methods.2018.NAACL.[PDF](https://arxiv.org/abs/1804.06876v1)
3. Analyze, Detect and Remove Gender Stereotyping from Bollywood Movies.2018.[PDF](http://proceedings.mlr.press/v81/madaan18a/madaan18a.pdf)
4. Learning Gender-Neutral Word Embeddings.2018.EMNLP.[PDF](https://arxiv.org/abs/1809.01496v1)
5. Large Scale Crowdsourcing and Characterization of Twitter Abusive Behavior.2018.[PDF](https://arxiv.org/abs/1802.00393)
6. Mitigating Unwanted Biases with Adversarial Learning.2018.[PDF](https://arxiv.org/abs/1801.07593)
7. The Knowref Coreference Corpus: Removing Gender and Number Cues for Difficult Pronominal Anaphora Resolution.2018.[PDF](https://arxiv.org/abs/1811.01747)
8. Mitigating Gender Bias in Natural Language Processing: Literature Review.2019.[PDF](https://arxiv.org/abs/1906.08976v1)
9. Gender Bias in Contextualized Word Embeddings.2019.[PDF](https://arxiv.org/abs/1904.03310)
10. It's All in the Name: Mitigating Gender Bias with Name-Based Counterfactual Data Substitution.2019.[PDF](https://arxiv.org/abs/1909.00871v3)
11. Counterfactual Data Augmentation for Mitigating Gender Stereotypes in Languages with Rich Morphology.2019.ACL.[PDF](https://arxiv.org/abs/1906.04571)
12. Getting Gender Right in Neural Machine Translation.2019.[PDF](https://arxiv.org/abs/1909.05088)
13. Equalizing Gender Bias in Neural Machine Translation with Word Embeddings Techniques.2019.[PDF](https://arxiv.org/abs/1901.03116)
14. Filling Gender & Number Gaps in Neural Machine Translation with Black-box Context Injection.2019.[PDF](https://arxiv.org/abs/1903.03467)
15. Reducing Gender Bias in Word-Level Language Models with a Gender-Equalizing Loss Function.2019.[PDF](https://arxiv.org/abs/1905.12801)
16. The Role of Protected Class Word Lists in Bias Identification of Contextualized Word Representations.2019.ACL.[PDF](https://www.aclweb.org/anthology/W19-3808/)
17. Conceptor Debiasing of Word Representations Evaluated on WEAT.2019.[PDF](https://arxiv.org/abs/1906.05993)
18. Gender-preserving Debiasing for Pre-trained Word Embeddings.2019.[PDF](https://arxiv.org/abs/1906.00742)
19. Examining Gender Bias in Languages with Grammatical Gender.2019.EMNLP.[PDF](https://arxiv.org/abs/1909.02224)
20. Generating Clues for Gender based Occupation De-biasing in Text.2019.[PDF](https://arxiv.org/abs/1804.03839)
21. Women, Politics and Twitter: Using Machine Learning to Change the Discourse.2019.[PDF](https://arxiv.org/abs/1911.11025) 
22. Resolving Gendered Ambiguous Pronouns with BERT.2019.[PDF](https://arxiv.org/abs/1906.01161)
23. Transfer Learning from Pre-trained BERT for Pronoun Resolution.2019.[PDF](https://www.aclweb.org/anthology/W19-3812/)
24. On GAP Coreference Resolution Shared Task: Insights from the 3rd Place Solution.2019.[PDF](https://www.aclweb.org/anthology/W19-3816/)
25. Gendered Pronoun Resolution Using BERT and an Extractive Question Answering Formulation.2019.[PDF](https://arxiv.org/abs/1906.03695)
26. BERT Masked Language Modeling for Co-reference Resolution.2019.[PDF](https://www.aclweb.org/anthology/W19-3811/)
27. Look Again at the Syntax: Relational Graph Convolutional Network for Gendered Ambiguous Pronoun Resolution.2019.[PDF](https://arxiv.org/abs/1905.08868)
28. MSnet:A BERT-based Network for Gendered Pronoun Resolution.2019.[PDF](https://arxiv.org/abs/1908.00308)
29. Fill the GAP: Exploiting BERT for Pronoun Resolution.2019.[PDF](https://www.aclweb.org/anthology/W19-3815/)
30. Anonymized BERT: An Augmentation Approach to the Gendered Pronoun Resolution Challenge.2019.[PDF](https://arxiv.org/abs/1905.01780)
31. Gendered Ambiguous Pronouns Shared Task: Boosting Model Confidence by Evidence Pooling.2019.[PDF](https://arxiv.org/abs/1906.00839)
32. Towards Understanding Gender Bias in Neural Relation Extraction.2020.ACL.[PDF](https://www.aclweb.org/anthology/2020.acl-main.265/) 
33. Reducing Gender Bias in Neural Machine Translation as a Domain Adaptation Problem.2020.ACL.[PDF](https://arxiv.org/abs/2004.04498)
34. A Causal Inference Method for Reducing Gender Bias in Word Embedding Relations.2020.AAAI.[PDF](https://arxiv.org/abs/1911.10787)
35. Double-Hard Debias: Tailoring Word Embeddings for Gender Bias Mitigation.2020.ACL.[PDF](https://arxiv.org/abs/2005.00965)
36. Mitigating Media Bias through Neutral Article Generation.2021.[PDF](https://arxiv.org/pdf/2104.00336.pdf)
37. Mitigating Political Bias in Language Models Through Reinforced Calibration.2021.AAAI.(Best Paper).[PDF](https://arxiv.org/abs/2104.14795)
38. Debiasing Pre-trained Contextualised Embeddings.2021.[PDF](https://arxiv.org/abs/2101.09523)




## Text de-bias

1. When He Doesn’t Mean You: GenderExclusive Language as Ostracism.2011.[PDF](https://www.wgalil.ac.il/files/GENDER/gendered_language_ostracism.pdf)
2. Can Gender Fair Language Reduce Gender Stereotyping and Discrimination?.2016.[HTML](https://www.frontiersin.org/articles/10.3389/fpsyg.2016.00025/full)
3. Connotation Frames of Power and Agency in Modern Films.2017.[PDF](https://www.aclweb.org/anthology/D17-1247/)
4. Style Transfer Through Back-Translation.2018.[PDF](https://www.aclweb.org/anthology/P18-1080/)
5. Proposed Taxonomy for Gender Bias in Text;A Filtering Methodology for the Gender Generalization Subtype.2019.[PDF](https://www.aclweb.org/anthology/W19-3802.pdf)
6. Queens are Powerful too: Mitigating Gender Bias in Dialogue Generation.2019.[PDF](https://arxiv.org/abs/1911.03842)
7. Contextual Affective Analysis: A Case Study of People Portrayals in Online #MeToo Stories.2019.[PDF](https://arxiv.org/pdf/1904.04164.pdf)
8. Queens are Powerful too: Mitigating Gender Bias in Dialogue Generation.2019.[PDF](https://arxiv.org/abs/1911.03842)
9. Automatic Gender Identification and Reinflection in Arabic.2019.[PDF](https://www.aclweb.org/anthology/W19-3822.pdf)
10. Counterfactual Data Augmentation for Mitigating Gender Stereotypes in Languages with Rich Morphology.2019.ACL.[PDF](https://www.aclweb.org/anthology/P19-1161/)
11. Multi-Dimensional Gender Bias Classification.2020.[PDF](https://arxiv.org/pdf/2005.00614.pdf)
12. Automatically Neutralizing Subjective Bias in Text.2020.AAAI.[PDF](https://ojs.aaai.org/index.php/AAAI/article/view/5385)
13. DivGAN: Towards Diverse Paraphrase Generation via Diversified Generative Adversarial Network.2020.[PDF](https://www.aclweb.org/anthology/2020.findings-emnlp.218/)
14. PowerTransformer: Unsupervised Controllable Revision for Biased Language Correction.2020.[PDF](https://arxiv.org/abs/2010.13816)
15. Plug and Play Language Models: A Simple Approach to Controlled Text Generation.2020.[PDF](https://arxiv.org/abs/1912.02164)
16. Self-Diagnosis and Self-Debiasing: A Proposal for Reducing Corpus-Based Bias in NLP.2021.[PDF](https://arxiv.org/pdf/2103.00453.pdf)
17. They, Them, Theirs: Rewriting with Gender-Neutral English.2021.[PDF](https://arxiv.org/pdf/2102.06788.pdf)

## Data set

1. Detecting Hate Speech on the World Wide Web.2012.[PDF](https://aclanthology.org/W12-2103.pdf)
2. Automated Dictionary Creation for Analyzing Text: An Illustration from Stereotype Content.2019.[PDF](https://psyarxiv.com/afm8k/)
3. Comprehensive stereotype content dictionaries using a semi-automated method.2020.[PDF](https://onlinelibrary.wiley.com/doi/epdf/10.1002/ejsp.2724)
4. GeBioToolkit: Automatic Extraction of Gender-Balanced Multilingual Corpus of Wikipedia Biographies.2020.[PDF](https://arxiv.org/abs/1912.04778v1)
5. Social Bias Frames: Reasoning about Social and Power Implications of Language.2020.[PDF](https://arxiv.org/abs/1911.03891)
6. StereoSet: Measuring Stereotypical Bias in Pretrained Language Models.2020.[PDF](https://arxiv.org/abs/2004.09456v1)
7. BOLD: Dataset and Metrics for Measuring Biases in Open-Ended Language Generation.2021.[PDF](https://arxiv.org/pdf/2101.11718.pdf)


## Conference
### EMNLP
1. Men Also Like Shopping: Reducing Gender Bias Amplification Using Corpus-level Constraints.2017.[PDF](https://arxiv.org/pdf/1707.09457.pdf)
2. De-Biased Court’s View Generation with Causality.2020.[PDF](https://www.aclweb.org/anthology/2020.emnlp-main.56)

## Comment 

1. Gender Bias and Sexism in Language.Oxford Research Encyclopedia of Communication.2017.[PDF](https://oxfordre.com/communication/view/10.1093/acrefore/9780190228613.001.0001/acrefore-9780190228613-e-470)
2. AI Can Be Sexist and Racist—It’s Time to Make It Fair.2018.Nature.[PDF](https://www.nature.com/articles/d41586-018-05707-8)

## Psychology

1. 偏见、歧视与刻板印象，有什么不一样?.[HTML](https://www.jianshu.com/p/b5c6465a9b73)
2. Implicit Bias: What It Means and How It Affects Behavior.[HTML](https://www.thoughtco.com/understanding-implicit-bias-4165634)

## Relevant literature

1. Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer.2020.[PDF](https://jmlr.org/papers/v21/20-074.html)


## Prompt
1. Exploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference.2021.EACL.[PDF](https://arxiv.org/abs/2001.07676)
2. It’s not just size that matters: Small language models are also few-shot learners.2021.NAACL.[PDF](https://arxiv.org/abs/2009.07118)
3. Making Pre-trained Language Models Better Few-shot Learners.2021.ACL.[PDF](https://arxiv.org/abs/2012.15723)

## Hate Speech & Abusive language & Cyberbullying
1. Automated Hate Speech Detection and the Problem of Offensive Language.2017.[PDF](https://arxiv.org/pdf/1703.04009.pdf)
2. Hateful Symbols or Hateful People? Predictive Features for Hate Speech Detection on Twitter.2016.NAACL.[PDF](https://aclanthology.org/N16-2013.pdf)
3. Content-Driven Detection of Cyberbullying on the Instagram Social Network.2016.[PDF](https://www.researchgate.net/profile/Haoti-Zhong/publication/313796198_Content-Driven_Detection_of_Cyberbullying_on_the_Instagram_Social_Network/links/58a65cc7aca27206d9a79e7a/Content-Driven-Detection-of-Cyberbullying-on-the-Instagram-Social-Network.pdf)



## MY LIST
1. Detecting Gender Stereotypes: Lexicon vs. Supervised Learning Methods.2020.ACM.[PDF](https://dl.acm.org/doi/abs/10.1145/3313831.3376488)
2. Implicitly Abusive Language – What does it actually look like and why are we not getting there?2021.NAACL.[PDF](https://www.aclweb.org/anthology/2021.naacl-main.48/)



