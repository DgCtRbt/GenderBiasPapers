# Gender Bias Papers
Must-read Papers on Gender Bias!

 <img src="https://www.hh-law.com/wp-content/uploads/sites/1300396/2019/11/implicitbiasimage.jpg" width = "600" height = "400" alt="" align=center />

## 偏见分析
1. Man Is to Computer Programmer as Woman Is to Homemaker? Debiasing Word Embeddings.2016.
2. Men Also Like Shopping: Reducing Gender Bias Amplification Using Corpus-level Constraints 2017. [PDF](https://arxiv.org/pdf/1707.09457.pdf)
3. Word Embeddings Quantify 100 Years of Gender and Ethnic Stereotypes.2018.[Dress](https://arxiv.org/abs/1711.08412v1).[Code](https://github.com/nikhgarg/EmbeddingDynamicStereotypes)
4. Understanding the Origins of Bias in Word Embeddings.2018.[Dress](https://arxiv.org/abs/1810.03611)
5. Is there Gender bias and stereotype in Portuguese Word Embeddings? 2018.[Dress](https://arxiv.org/abs/1810.04528)
6. Learning Gender-Neutral Word Embeddings.EMNLP.2018.[Dress](https://arxiv.org/abs/1809.01496v1)
7. Measuring Societal Biases from Text Corpora with Smoothed First-Order Co-occurrence.2018.[Dress](https://arxiv.org/abs/1812.10424)
8. Measuring and Mitigating Unintended Bias in Text Classification.AAAI.2018
9. Gender Bias in Sentiment Analysis.2018.[Dress](https://wlv.openrepository.com/bitstream/handle/2436/620633/GenderBiasInSentimentAnalysisPreprint.pdf?sequence=9&isAllowed=y)
10. Examining Gender and Race Bias in Two Hundred Sentiment Analysis Systems.2018.
11. Good Secretaries, Bad Truck Drivers? Occupational Gender Stereotypes in Sentiment Analysis.2019.[Dress](https://arxiv.org/abs/1906.10256v2)
12. Gender Bias in Contextualized Word Embeddings.2019.[Dress](https://arxiv.org/abs/1904.03310)
13. Evaluating the Underlying Gender Bias in Contextualized Word Embeddings.2019.[Dress](https://arxiv.org/abs/1904.08783)
14. Measuring Bias in Contextualized Word Representations.2019.[Dress](https://arxiv.org/abs/1906.07337v1)
15. Examining the Presence of Gender Bias in Customer Reviews Using Word Embedding. 2019.[Dress](https://arxiv.org/abs/1902.00496v1)
16. Using Word Embeddings to Examine Gender Bias in Dutch Newspapers, 1950-1990. 2019.[Dress](https://www.aclweb.org/anthology/W19-4712/)
17. How Does Grammatical Gender Affect Noun Representations in Gender-Marking Languages? 2019. [PDF](https://arxiv.org/pdf/1910.14161.pdf)
18. Quantifying the Semantic Core of Gender Systems.EMNLP 2019 [PDF](https://arxiv.org/pdf/1910.13497.pdf)
19. Relating Word Embedding Gender Biases to Gender Gaps: A Cross-Cultural Analysis.ACL.2019.[Dress](https://www.aclweb.org/anthology/W19-3803/)
20. Towards Understanding Gender Bias in Neural Relation Extraction. ACL. 2020. [Dress](https://www.aclweb.org/anthology/2020.acl-main.265/)
21. Investigating Potential Factors Associated with Gender Discrimination in Collaborative Recommender Systems.2020.[Dress](https://arxiv.org/abs/2002.07786)

## 偏见的刻画和测量
1. First Women, Second Sex: Gender Bias in Wikipedia. 2015
2. It's A Man's Wikipedia? Assessing Gender Inequality in An Online Encyclopedia. 2015
3. Social Bias in Elicited Natural Language Inference. 2017
4. Finding Microaggressions in the Wild: A Case for Locating Elusive Phenomena in Social Media Posts.2019
5. Mitigating Gender Bias in Natural Language Processing: Literature Review.2019[Dress](https://arxiv.org/abs/1906.08976v1)
6. Measuring Individual Differences in Implicit Cognition: The Implicit Association Test. 1998.
7. National Differences in Gender–science Stereotypes Predict National Sex Differences in Science and Math Achievement.2009.
8. Semantics Derived Automatically from Language Corpora Contain Human-like Biases. 2017.
9. Assessing Social and Intersectional Biases in Contextualized Word Representations. NIPS.2019
10. Measuring Gender Bias in Word Embeddings across Domains and Discovering New Gender Bias Word Categories.2019
11. On Measuring Social Biases in Sentence Encoders.2019
12. Black Is to Criminal as Caucasian Is to Police: Detecting and Removing Multiclass Bias in Word Embeddings.2019.
13. Lipstick on A Pig: Debiasing Methods Cover up Systematic Gender Biases in Word Embeddings but Do Not Remove Them.2019
14. Gender Bias in Neural Natural Language Processing.2018[Dress](https://arxiv.org/abs/1807.11714)
15. Reducing Gender Bias in Abusive Language Detection.2018.
16. Gender Bias in Coreference Resolution.2018
17. [Mind the GAP: A Balanced Corpus of Gendered Ambiguous Pronouns](https://watermark.silverchair.com/tacl_a_00240.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAAAqkwggKlBgkqhkiG9w0BBwagggKWMIICkgIBADCCAosGCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQMPE7Kg3Ht5MYve550AgEQgIICXP0XeqeYbNwTfeu-j1c7Q84pHmZAqEziDs0r7WXaeGBx5LZkRmuTp5wWdWdxFj1tqwjN3l74QyTiz7PiN066qi2gOOvAqATNT07KTu5y-R-2SPSD_ExZBGdkKDnkyGm3zIXwJ7zx7FC78Ud5b-2c5LdYNC7dyBd_4Te-ca3hwUzilZqAezF-IwBTrPTt5to0M-B10aAfHCjgxQRxui_cTtS20pDtnQEor6G9vhZwF9ckwVb47CYSqt4qoL1jDuBMTRuRiKBnr7Qp2pI6YLfRz7gtaB6plzaU_3i6tWXcO4HHPx7K3o0JbJAREUSQ3R9PAPyuUCihdQ6LtxHKRL8QEbZ5rsjSqa4_KgFDgsF7R1gycfsS1g0opxrLXQKpLrZ4ZrQTODPubSewo1Bl0jw_Yy9kKTTYCrrboEQZpwR1f7wThslo5PrykUlIwf-usJ_VP2z1ysV7wZWKQ7jYt7whsj1RNBfnn5JmwGZIOeGSvybhrfipV3qQ1LkiN1vn3XytCY9kYgohgcPyQuZWa4kAVKN5_Un32s3Ijc-7pY8y4MlA-HRfw4IZkpNpKQI2PMGThZZ2RWjJDW7z1mWvKc3-DLH_pRs56OwVTMUEYh5DoCjl57UxLgK9fhVgQGGhlpzQflDCkM-381s_j0KJV-R2aVucdagpOBNlKPriqdH3SCvvw60TEtNH9uALDxpd8AONrOXvOkW3zQvgbni-96SzWcGr6lEfVFo5g5wf8pDnMhYNVfmGEHJ476lMFdwdzaolMJ360aAGMx2s96rDmEl1EQxsSObYhfDFx1H00fo).2018.
18. 数据集[GeBioToolkit: Automatic Extraction of Gender-Balanced Multilingual Corpus of Wikipedia Biographies](https://xueshu.baidu.com/usercenter/paper/show?paperid=1w780m40b22108x02s2h0mt06r479606&site=xueshu_se&hitarticle=1).2020
19. Toward Gender-inclusive Coreference Resolution.2019

## 偏见消除
1. Mitigating Gender Bias in Natural Language Processing: Literature Review.2019.[Dress](https://arxiv.org/abs/1906.08976v1)
2. Gender Bias in Coreference Resolution: Evaluation and Debiasing Methods.NAACL.2018[Dress](https://arxiv.org/abs/1804.06876v1)
3. Towards Understanding Gender Bias in Neural Relation Extraction. ACL. 2020. [Dress](https://www.aclweb.org/anthology/2020.acl-main.265/)
4. Gender Bias in Contextualized Word Embeddings.2019.[Dress](https://arxiv.org/abs/1904.03310)
5. It's All in the Name: Mitigating Gender Bias with Name-Based Counterfactual Data Substitution.2019.[Dress](https://arxiv.org/abs/1909.00871v3)
6. Counterfactual Data Augmentation for Mitigating Gender Stereotypes in Languages with Rich Morphology.ACL.2019.[Dress](https://arxiv.org/abs/1906.04571)
7. Analyze, Detect and Remove Gender Stereotyping from Bollywood Movies.2018.
8. Getting Gender Right in Neural Machine Translation.2019.[Dress](https://arxiv.org/abs/1909.05088)
9. Reducing Gender Bias in Neural Machine Translation as a Domain Adaptation Problem.ACL.2020.[Dress](https://arxiv.org/abs/2004.04498)
10. Equalizing Gender Bias in Neural Machine Translation with Word Embeddings Techniques.2019.[Dress](https://arxiv.org/abs/1901.03116)
11. Filling Gender & Number Gaps in Neural Machine Translation with Black-box Context Injection.2019.[Dress](https://arxiv.org/abs/1903.03467)
12. Large Scale Crowdsourcing and Characterization of Twitter Abusive Behavior.2018.[Dress](https://arxiv.org/abs/1802.00393)
13. Hateful Symbols or Hateful People? Predictive Features for Hate Speech Detection on Twitter.
14. Examining Gender Bias in Languages with Grammatical Gender.EMNLP.2019.[Dress](https://arxiv.org/abs/1909.02224)
15. Gender-preserving Debiasing for Pre-trained Word Embeddings.2019.[Dress](https://arxiv.org/abs/1906.00742)
16. Conceptor Debiasing of Word Representations Evaluated on WEAT.2019.[Dress](https://arxiv.org/abs/1906.05993)
17. The Role of Protected Class Word Lists in Bias Identification of Contextualized Word Representations.ACL.2019.[Dress](https://www.aclweb.org/anthology/W19-3808/)
18. A Causal Inference Method for Reducing Gender Bias in Word Embedding Relations.AAAI. 2020.[Dress](https://arxiv.org/abs/1911.10787)
19. Double-Hard Debias: Tailoring Word Embeddings for Gender Bias Mitigation.ACL.2020.[Dress](https://arxiv.org/abs/2005.00965)
20. Learning Gender-Neutral Word Embeddings.EMNLP.2018.[Dress](https://arxiv.org/abs/1809.01496v1)
21. Reducing Gender Bias in Word-Level Language Models with a Gender-Equalizing Loss Function.2019.[Dress](https://arxiv.org/abs/1905.12801)
22. Mitigating Unwanted Biases with Adversarial Learning.2018.[Dress](https://arxiv.org/abs/1801.07593)
23. Queens are Powerful too: Mitigating Gender Bias in Dialogue Generation.2019.[Dress](https://arxiv.org/abs/1911.03842)
24. Resolving Gendered Ambiguous Pronouns with BERT.2019.[Dress](https://arxiv.org/abs/1906.01161)
25. Look Again at the Syntax: Relational Graph Convolutional Network for Gendered Ambiguous Pronoun Resolution.2019.[Dress](https://arxiv.org/abs/1905.08868)
26. On GAP Coreference Resolution Shared Task: Insights from the 3rd Place Solution.2019.[Dress](https://www.aclweb.org/anthology/W19-3816/)
27. Transfer Learning from Pre-trained BERT for Pronoun Resolution.2019.[Dress](https://www.aclweb.org/anthology/W19-3812/)
28. Gendered Pronoun Resolution Using BERT and an Extractive Question Answering Formulation.2019.[Dress](https://arxiv.org/abs/1906.03695)
29. 完形填空：BERT Masked Language Modeling for Co-reference Resolution.2019.[Dress](https://www.aclweb.org/anthology/W19-3811/)
30. MSnet:A BERT-based Network for Gendered Pronoun Resolution.2019.[Dress](https://arxiv.org/abs/1908.00308)
31. Fill the GAP: Exploiting BERT for Pronoun Resolution.2019.[Dress](https://www.aclweb.org/anthology/W19-3815/)
32. Anonymized BERT: An Augmentation Approach to the Gendered Pronoun Resolution Challenge.2019.[Dress](https://arxiv.org/abs/1905.01780)
33. Gendered Ambiguous Pronouns Shared Task: Boosting Model Confidence by Evidence Pooling.2019.[Dress](https://arxiv.org/abs/1906.00839)
34. Generating Clues for Gender based Occupation De-biasing in Text.2019.[Dress](https://arxiv.org/abs/1804.03839)
35. Women, Politics and Twitter: Using Machine Learning to Change the Discourse.2019.[Dress](https://arxiv.org/abs/1911.11025)
36. Mitigating Media Bias through Neutral Article Generation.2021.[Dress](https://arxiv.org/pdf/2104.00336.pdf)



## COMMENT 
1. Menegatti M, Rubini M. Gender Bias and Sexism in Language[M]//Oxford Research Encyclopedia of Communication. 2017. [Dress](https://oxfordre.com/communication/view/10.1093/acrefore/9780190228613.001.0001/acrefore-9780190228613-e-470)
2. James Z, Londa S.  AI Can Be Sexist and Racist—It’s Time to Make It Fair[J]. Nature, 2018. [Dress](https://www.nature.com/articles/d41586-018-05707-8)

## 心理学
[偏见、歧视与刻板印象，有什么不一样？高浩容](https://www.jianshu.com/p/b5c6465a9b73)
