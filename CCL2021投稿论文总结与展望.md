# CCL2021投稿论文总结与展望

2021.4.18

## 1. 总结

### 论文的工作

我们首先构建了一个以性别称谓词为关键字中文的性别无偏数据集,然后利用掩码语言模型(Masked Language Model)遮盖掉性别关键字,输入模型预测性别关键字概率,对比男女性别以此判断模型的性别偏见程度。

<img src="https://i.loli.net/2021/04/18/UquSezIVfL8WJYH.png" style="zoom: 67%;" />

<center>工作流程图。

### 结果

![](https://i.loli.net/2021/04/18/bSNpLTid2ck9DZ6.png)

<center>5个预训练模型对每个句子预测的性别偏见程度分布（注：图中横坐标表示数据集 中20000条句子的序号，纵坐标表示单句的偏见程度。大于0为偏向男性，小于0偏向女性，趋向 于0表示偏向中性。

我们所选择的5个中文预训练模型主要还是集中在预 测中性的语境趋势上。但对于一些句子，模型预测还是一致偏向男性或女性，说明中文预训练 模型学习到了这些句子中强烈的偏向男性或女性的语境。

### 案例研究：模型对“男童”和“女童”的偏见分析

![](https://i.loli.net/2021/04/18/v8fFDHGrQRBqkYt.png)

![](https://i.loli.net/2021/04/18/tE53SNjdLJlmyVr.png)

我们选择了“男女”关键词对中含有“男童”和“女童”的句子。从结果中筛选出偏向“男童”的 有78条句子，偏向“女童”的有158条句子。按照偏见程度排序，其中偏向“男”和“女”的前六句， 结果分别Table 7和Table 8所示。对比偏向“男童”和“女童”的句子语境我们发现了与之前类似的 情况。偏向“男童”的语境与“调皮”、“闯祸”和“意外受伤”等信息有关，而偏向到“女童”的句子 则反映了女性儿童“需要保护”和“被性侵”等情况。这说明BERT-base模型学到了文本中的深层 次的语境偏见信息。

## 2.展望

### 未来工作

预训练语言模型中的性别偏见又可分为分配性偏见和表征性偏见。就自然语言处理系 统而言，模型在数据较多的一方效果会更好，这种偏见就是分配性偏见；当模型通过上下文信 息于性别关键词产生关联时，这种偏见就是表征性偏见

在文本中如何对偏见的类型进行识别和分类是一个值得研究的问题。